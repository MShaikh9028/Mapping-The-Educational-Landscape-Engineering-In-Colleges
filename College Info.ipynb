{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: HTTPSConnectionPool(host='www.careers360.com', port=443): Max retries exceeded with url: /colleges/dev-samaj-college-for-women-chandigarh (Caused by ResponseError('too many 500 error responses'))\n",
      "Request failed: 404 Client Error: Not Found for url: https://www.careers360.com/colleges/ha-degree-college-farrukhabad\n",
      "Request failed: HTTPSConnectionPool(host='www.careers360.com', port=443): Max retries exceeded with url: /colleges/indo-global-college-of-engineering-mohali (Caused by ResponseError('too many 500 error responses'))\n",
      "Request failed: 404 Client Error: Not Found for url: https://www.careers360.com/colleges/ramappa-engineering-college-waranga\n",
      "Request failed: 404 Client Error: Not Found for url: https://www.careers360.com/colleges/school-of-architecture-and-planning-gd-goenka-university-gurugram\n",
      "Request failed: 404 Client Error: Not Found for url: https://www.careers360.com/university/7-star-academy-kolkata\n",
      "Request failed: HTTPSConnectionPool(host='www.careers360.com', port=443): Max retries exceeded with url: /colleges/sundargarh-engineering-college-sundargarh (Caused by ResponseError('too many 500 error responses'))\n",
      "Extracted 9000 rows.\n",
      "Scraping completed! Data saved to College Info.csv\n",
      "                                        College Name  \\\n",
      "0  AAA College of Engineering and Technology, Siv...   \n",
      "1       Aadishwar College of Technology, Gandhinagar   \n",
      "2  AAERT and SSB Faculty of Architecture, Sarvaja...   \n",
      "3           Aakar Academy of Architecture, Bangalore   \n",
      "4  Aalim Muhammed Salegh Academy of Architecture,...   \n",
      "\n",
      "                                         Description  \n",
      "0  AAA College of Engineering and Technology, Siv...  \n",
      "1  Aadoishwar College of Technology, Gandhinagar,...  \n",
      "2  The constituent colleges of repute in Gujarat ...  \n",
      "3  Aakar Academy of Architecture is architectural...  \n",
      "4  The Aalim Muhammed Salegh Academy of Architect...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Base URL for scraping engineering colleges\n",
    "BASE_URL = \"https://engineering.careers360.com/colleges/list-of-engineering-colleges-in-india?page={}&sort_by=4\"\n",
    "\n",
    "# Headers to mimic a browser request\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# Total pages to scrape\n",
    "TOTAL_PAGES = 180  # Change this for more pages\n",
    "\n",
    "# Setup retry strategy for handling connection issues\n",
    "RETRY_STRATEGY = Retry(\n",
    "    total=5,  # Retry up to 5 times\n",
    "    backoff_factor=1,  # Exponential backoff (1s, 2s, 4s, etc.)\n",
    "    status_forcelist=[500, 502, 503, 504, 429],  # Retry on these HTTP errors\n",
    "    allowed_methods=[\"GET\"],  # Only apply retries to GET requests\n",
    ")\n",
    "\n",
    "# Create a session with retry adapter\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    adapter = HTTPAdapter(max_retries=RETRY_STRATEGY)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.headers.update(HEADERS)\n",
    "    return session\n",
    "\n",
    "# Function to fetch and parse HTML content\n",
    "def fetch_soup(url, session):\n",
    "    try:\n",
    "        response = session.get(url, timeout=10)  # 10s timeout\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.text, \"html.parser\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract text utility function\n",
    "def extract_text(tag, selector, attr=None):\n",
    "    element = tag.select_one(selector)\n",
    "    return element.get(attr) if attr else element.text.strip() if element else \"N/A\"\n",
    "\n",
    "# Extract first <p> element from the college description page\n",
    "def extract_first_paragraph(soup):\n",
    "    about_section = soup.find(\"div\", {\"data-testid\": \"college_about\"})\n",
    "    if about_section:\n",
    "        first_p = about_section.find(\"p\")\n",
    "        return first_p.text.strip() if first_p else \"N/A\"\n",
    "    return \"N/A\"\n",
    "\n",
    "# Function to scrape a single page\n",
    "def scrape_page(page, session):\n",
    "    soup = fetch_soup(BASE_URL.format(page), session)\n",
    "    if not soup:\n",
    "        print(f\"Page {page} returned no data. Check if the website structure has changed.\")\n",
    "        return []\n",
    "\n",
    "    data = []\n",
    "    for card in soup.select(\"div.card_block\"):\n",
    "        # Extract basic details\n",
    "        name = extract_text(card, \"h3 a\")\n",
    "\n",
    "        # Extract college details URL and parse it\n",
    "        college_url = urljoin(BASE_URL, extract_text(card, \"h3 a\", \"href\"))\n",
    "        college_soup = fetch_soup(college_url, session)\n",
    "        college_description = extract_first_paragraph(college_soup) if college_soup else \"N/A\"\n",
    "\n",
    "        # Store extracted data in a structured format\n",
    "        data.append({\n",
    "            \"College Name\": name,\n",
    "            \"Description\": college_description,  # Extracted first <p> element\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Run the scraper with a session and ThreadPoolExecutor\n",
    "def main():\n",
    "    session = create_session()  # Create a session with retries\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = list(executor.map(lambda p: scrape_page(p, session), range(1, TOTAL_PAGES + 1)))\n",
    "\n",
    "    session.close()  # Close session when done\n",
    "\n",
    "    # Flatten list and convert to DataFrame\n",
    "    df = pd.DataFrame([item for sublist in results for item in sublist])\n",
    "\n",
    "    # Debug: Check if DataFrame is empty\n",
    "    if df.empty:\n",
    "        print(\"No data extracted! Check selectors or if the website is blocking requests.\")\n",
    "    else:\n",
    "        print(f\"Extracted {df.shape[0]} rows.\")\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(\"College Info.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Scraping completed! Data saved to College Info.csv\")\n",
    "    print(df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
