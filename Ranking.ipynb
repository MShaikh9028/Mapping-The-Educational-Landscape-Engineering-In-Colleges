{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed! Data saved to optimized_NIRF_ranking.csv\n",
      "                                        College Name NIRF Ranking\n",
      "0  IIT Madras (IITM) - Indian Institute of Techno...            1\n",
      "1   IIT Delhi - Indian Institute of Technology Delhi            2\n",
      "2  IIT Bombay - Indian Institute of Technology Bo...            3\n",
      "3  IIT Kanpur - Indian Institute of Technology Ka...            4\n",
      "4  IIT Kharagpur - Indian Institute of Technology...            5\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "# Base URL for pagination\n",
    "BASE_URL = \"https://engineering.careers360.com/colleges/list-of-engineering-colleges-in-india?page={}&sort_by=3&stream=1\"\n",
    "\n",
    "# Headers to mimic a real browser (to prevent blocking)\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# Total number of pages to scrape\n",
    "TOTAL_PAGES = 3\n",
    "\n",
    "# Setup retry strategy\n",
    "RETRY_STRATEGY = Retry(\n",
    "    total=5,  # Retry up to 5 times\n",
    "    backoff_factor=1,  # Waits 1s, 2s, 4s, 8s, etc.\n",
    "    status_forcelist=[500, 502, 503, 504, 429],  # Retries on these HTTP errors\n",
    "    allowed_methods=[\"GET\"],\n",
    ")\n",
    "\n",
    "# Create a session with retry adapter\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    adapter = HTTPAdapter(max_retries=RETRY_STRATEGY)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "# Function to scrape a single page\n",
    "def scrape_page(page, session):\n",
    "    url = BASE_URL.format(page)\n",
    "    try:\n",
    "        response = session.get(url, headers=HEADERS, timeout=10)  # 10s timeout\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page {page} - Status Code: {response.status_code}\")\n",
    "            return []\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed for page {page}: {e}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    colleges = []\n",
    "\n",
    "    for card in soup.find_all(\"div\", class_=\"card_block\"):\n",
    "        name = card.find(\"h3\", class_=\"college_name d-md-none\")\n",
    "        rank = card.find(\"div\", class_=\"ranking_strip d-md-none\")\n",
    "        nirf_rank = rank.find(\"strong\") if rank else None\n",
    "\n",
    "        colleges.append({\n",
    "            \"College Name\": name.get_text(strip=True) if name else \"N/A\",\n",
    "            \"NIRF Ranking\": nirf_rank.get_text(strip=True) if nirf_rank else \"N/A\"\n",
    "        })\n",
    "\n",
    "    return colleges\n",
    "\n",
    "# Run scraper with session and ThreadPoolExecutor\n",
    "def main():\n",
    "    session = create_session()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = executor.map(lambda p: scrape_page(p, session), range(1, TOTAL_PAGES + 1))\n",
    "\n",
    "    session.close()  # Close session after use\n",
    "\n",
    "    # Flatten list and save data\n",
    "    df = pd.DataFrame([college for result in results for college in result])\n",
    "    df.to_csv(\"Ranking.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(\"Scraping completed! Data saved to Ranking.csv\")\n",
    "    print(df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
