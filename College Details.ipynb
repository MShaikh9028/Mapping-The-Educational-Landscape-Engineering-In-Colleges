{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Extracted 440 rows.\n",
      "Scraping completed! Data saved to Course Detail.csv\n",
      "                                        College Name  \\\n",
      "0  AAA College of Engineering and Technology, Siv...   \n",
      "1  AAA College of Engineering and Technology, Siv...   \n",
      "2  AAA College of Engineering and Technology, Siv...   \n",
      "3  AAA College of Engineering and Technology, Siv...   \n",
      "4  AAA College of Engineering and Technology, Siv...   \n",
      "\n",
      "                   Location College Type Rating  \\\n",
      "0  Virudhunagar, Tamil Nadu      Private  5.0/5   \n",
      "1  Virudhunagar, Tamil Nadu      Private  5.0/5   \n",
      "2  Virudhunagar, Tamil Nadu      Private  5.0/5   \n",
      "3  Virudhunagar, Tamil Nadu      Private  5.0/5   \n",
      "4  Virudhunagar, Tamil Nadu      Private  5.0/5   \n",
      "\n",
      "                                        Courses Duration Fee Structure  \\\n",
      "0           BE Computer Science and Engineering  4 Years           N/A   \n",
      "1                     BE Mechanical Engineering  4 Years           N/A   \n",
      "2  BE Electronics and Communication Engineering  4 Years           N/A   \n",
      "3     BE Electrical and Electronics Engineering  4 Years           N/A   \n",
      "4                          BE Civil Engineering  4 Years           N/A   \n",
      "\n",
      "     Seats  \n",
      "0  4 Years  \n",
      "1  4 Years  \n",
      "2  4 Years  \n",
      "3  4 Years  \n",
      "4  4 Years  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "# Base URL\n",
    "BASE_URL = \"https://engineering.careers360.com/colleges/list-of-engineering-colleges-in-india?page={}&sort_by=4\"\n",
    "\n",
    "# Headers to mimic a browser request\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# Total pages to scrape\n",
    "TOTAL_PAGES = 180\n",
    "\n",
    "# Setup retry strategy for handling connection issues\n",
    "RETRY_STRATEGY = Retry(\n",
    "    total=5,  # Retry up to 5 times\n",
    "    backoff_factor=1,  # Wait 1s, 2s, 4s, 8s, etc., between retries\n",
    "    status_forcelist=[500, 502, 503, 504, 429],  # Retry on these HTTP errors\n",
    "    allowed_methods=[\"GET\"],  # Apply only to GET requests\n",
    ")\n",
    "\n",
    "# Create a session with retry adapter\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    adapter = HTTPAdapter(max_retries=RETRY_STRATEGY)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "# Function to fetch and parse HTML content\n",
    "def fetch_soup(url, session):\n",
    "    try:\n",
    "        response = session.get(url, headers=HEADERS, timeout=10)  # 10s timeout\n",
    "        if response.status_code == 200:\n",
    "            return BeautifulSoup(response.text, \"html.parser\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "    return None\n",
    "\n",
    "# Extract text utility function\n",
    "def extract_text(tag, selector, attr=None):\n",
    "    element = tag.select_one(selector)\n",
    "    return element.get(attr) if attr else element.text.strip() if element else \"N/A\"\n",
    "\n",
    "# Function to scrape a single page\n",
    "def scrape_page(page, session):\n",
    "    soup = fetch_soup(BASE_URL.format(page), session)\n",
    "    if not soup:\n",
    "        return []\n",
    "\n",
    "    data = []\n",
    "    for card in soup.select(\"div.card_block\"):\n",
    "        # Extract basic details\n",
    "        name = extract_text(card, \"h3 a\")\n",
    "        location = extract_text(card, \"div.content_block.d-block.d-md-none span\")\n",
    "        rating = extract_text(card, \"span.star_text\")\n",
    "        college_type = extract_text(card, \"div.content_block.d-none.d-md-block span:nth-of-type(2)\")\n",
    "\n",
    "        # Extract facilities URL but avoid extra requests if unnecessary\n",
    "        facilities = \"N/A\"\n",
    "        facilities_link = next((a[\"href\"] for a in card.select(\"div.d-none.d-md-block a\") if \"facilities\" in a[\"href\"]), None)\n",
    "        if facilities_link:\n",
    "            facilities_url = f\"https://www.careers360.com{facilities_link}\" if not facilities_link.startswith(\"http\") else facilities_link\n",
    "            facilities_soup = fetch_soup(facilities_url, session)\n",
    "            if facilities_soup:\n",
    "                facilities = \", \".join([f.text.strip() for f in facilities_soup.select(\"span.facilities_name\")])\n",
    "\n",
    "        # Store extracted data\n",
    "        data.append({\n",
    "            \"College Name\": name,\n",
    "            \"Location\": location,\n",
    "            \"College Type\": college_type,\n",
    "            \"Facilities\": facilities,\n",
    "            \"Rating\": rating\n",
    "        })\n",
    "\n",
    "    return data\n",
    "\n",
    "# Run the scraper with a session and ThreadPoolExecutor\n",
    "def main():\n",
    "    session = create_session()  # Create a session with retries\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:  # Reduce max_workers\n",
    "        results = list(executor.map(lambda p: scrape_page(p, session), range(1, TOTAL_PAGES + 1)))\n",
    "\n",
    "    session.close()  # Close session when done\n",
    "\n",
    "    # Flatten list and convert to DataFrame\n",
    "    df = pd.DataFrame([item for sublist in results for item in sublist])\n",
    "\n",
    "        # Debug: Check if DataFrame is empty\n",
    "    if df.empty:\n",
    "        print(\"No data extracted! Check selectors or if the website is blocking requests.\")\n",
    "    else:\n",
    "        print(f\"Extracted {df.shape[0]} rows.\")\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(\"College Details.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Scraping completed! Data saved to College Details.csv\")\n",
    "    print(df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
